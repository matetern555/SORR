# ğŸ¯ Instrukcja konfiguracji oceny rozmÃ³w

## âœ… Co zostaÅ‚o zaimplementowane

1. **Model bazy danych** (`app/models/evaluation.py`):
   - Tabela `evaluations` - gÅ‚Ã³wna ocena rozmowy
   - Tabela `category_scores` - oceny po kategoriach
   - Tabela `quotes` - cytaty (dowody) z kategorii

2. **Schematy Pydantic** (`app/schemas/evaluation.py`):
   - `EvaluationResult` - peÅ‚ny wynik oceny
   - `CategoryScore` - ocena kategorii
   - `Quote` - cytat

3. **Serwis oceny** (`app/services/evaluation.py`):
   - Integracja z GPT-4
   - 6 kategorii SERVICE zgodnie ze specyfikacjÄ…
   - System prompt zgodny ze specyfikacjÄ…
   - Obliczanie wynikÃ³w i ocen literowych

4. **Endpointy API** (`app/api/endpoints/evaluation.py`):
   - `POST /api/evaluation/evaluate/{transcription_id}` - ocena rozmowy
   - `GET /api/evaluation/evaluations/{transcription_id}` - pobierz ocenÄ™
   - `GET /api/evaluation/evaluations/` - lista wszystkich ocen

## âš™ï¸ Konfiguracja

### 1. Dodaj klucz API OpenAI

OtwÃ³rz plik `app/services/evaluation.py` i znajdÅº funkcjÄ™ `get_openai_client()`:

```python
def get_openai_client():
    """Tworzy i zwraca klienta OpenAI"""
    # TODO: UsunÄ…Ä‡ hardkod po naprawie pliku .env
    api_key = os.getenv("OPENAI_API_KEY") or "sk-proj-..."
    
    if not api_key or api_key == "sk-proj-...":
        raise ValueError("Brak klucza API OpenAI. SprawdÅº plik .env lub dodaj klucz bezpoÅ›rednio w kodzie")
    
    return OpenAI(api_key=api_key)
```

**ZamieÅ„** `"sk-proj-..."` na **TwÃ³j prawdziwy klucz API OpenAI**.

### 2. Zainstaluj wymagane biblioteki

```bash
.\venv\Scripts\pip.exe install openai
```

### 3. Zrestartuj serwer

```bash
# Zatrzymaj serwer (Ctrl+C) i uruchom ponownie:
.\venv\Scripts\python.exe -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

## ğŸ§ª Testowanie

### SprawdÅº dostÄ™pne endpointy

```bash
.\venv\Scripts\python.exe -c "import requests; api = requests.get('http://localhost:8000/openapi.json').json(); paths = [p for p in api['paths'].keys() if 'evaluation' in p]; print('Endpoints:'); [print('  -', p) for p in paths]"
```

PowinieneÅ› zobaczyÄ‡:
```
Endpoints:
  - /api/evaluation/evaluate/{transcription_id}
  - /api/evaluation/evaluations/{transcription_id}
  - /api/evaluation/evaluations/
```

### OceÅ„ rozmowÄ™

```bash
.\venv\Scripts\python.exe -c "import requests; response = requests.post('http://localhost:8000/api/evaluation/evaluate/1?scorecard_type=SERVICE'); print('Status:', response.status_code); print('Response:', response.json())"
```

## ğŸ“Š Kategorie oceny (SERVICE)

1. **Powitanie i ton** (10%) - pierwsze wraÅ¼enie
2. **Identyfikacja problemu** (20%) - trafne pytania i potwierdzenie
3. **RozwiÄ…zanie sprawy** (25%) - skutecznoÅ›Ä‡ i jasnoÅ›Ä‡ pomocy
4. **JasnoÅ›Ä‡ komunikacji** (15%) - prosty jÄ™zyk, tempo
5. **Finalizacja rozmowy** (15%) - domkniÄ™cie i pozytywne zakoÅ„czenie
6. **Soft-skills** (15%) - empatia, cierpliwoÅ›Ä‡

## ğŸ“ˆ Skala ocen

- **A** - 85-100% - Wzorowo
- **B** - 75-84% - Dobrze
- **C** - 60-74% - Poprawnie
- **D** - <60% - Wymaga poprawy

## ğŸ“ Co zwraca GPT-4

Dla kaÅ¼dej kategorii:
- Ocena 1-5
- KrÃ³tki komentarz
- 1-2 cytaty z czasem

Dodatkowo:
- Sentyment klienta (start, end, delta, cytat)
- Sentyment konsultanta (start, end, delta, cytat)
- Komentarz koÅ„cowy (2-4 zdania)

## ğŸ”§ RozwiÄ…zywanie problemÃ³w

### BÅ‚Ä…d: "Brak klucza API OpenAI"
- SprawdÅº czy klucz zostaÅ‚ dodany w `app/services/evaluation.py`
- Upewnij siÄ™ Å¼e klucz jest poprawny

### BÅ‚Ä…d: "Brak segmentÃ³w mÃ³wcÃ³w"
- Najpierw wykonaj diaryzacjÄ™: `POST /api/diarization/analyze/{transcription_id}`
- Dopiero potem ocenÄ™

### BÅ‚Ä…d: "Transkrypcja nie znaleziona"
- SprawdÅº czy transkrypcja o podanym ID istnieje
- Najpierw przeÅ›lij audio i wykonaj transkrypcjÄ™

## ğŸ“ NastÄ™pne kroki

Po poprawnym skonfigurowaniu moÅ¼esz:
1. PrzetestowaÄ‡ ocenÄ™ na przykÅ‚adowej rozmowie
2. SprawdziÄ‡ wynik w bazie danych
3. WygenerowaÄ‡ raporty i dashboard
4. DodaÄ‡ pozostaÅ‚e karty oceny (SALES, RETENTION, COLLECTIONS)

